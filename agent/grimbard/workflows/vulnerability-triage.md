# Vulnerability Triage Workflow

**Duration**: 30-60 minutes
**Purpose**: Prioritize and organize existing SARIF security findings into actionable remediation plan
**Input**: Directory containing SARIF files from security scans
**Output**: Prioritized backlog with severity rankings, false positive filtering, and remediation guidance

---

## Overview

The Vulnerability Triage workflow processes existing SARIF files from multiple security tools to create a prioritized, actionable backlog. This workflow is essential when:

- You have accumulated SARIF files from multiple scan runs
- Different teams have run different security tools
- You need to merge findings from various sources
- Historical scan data needs prioritization
- Sprint planning requires security backlog grooming

This is **Phase 3 only** of the complete security review, focused exclusively on organizing and prioritizing existing findings.

---

## Prerequisites

### Required Input

- **SARIF Files**: One or more `.sarif` files from security scanning tools
- **SARIF Tools**: Python `sarif-tools` package for processing

### Installation

```bash
# Install SARIF processing tools
pip install sarif-tools

# Verify installation
python -m sarif_tools --version
```

### Expected SARIF Sources

This workflow processes SARIF from any tool:

- **Opengrep/Semgrep** - Code security findings
- **Gitleaks** - Secrets and credentials
- **KICS** - Infrastructure as Code issues
- **Noir** - API attack surface
- **OSV-Scanner** - Dependency vulnerabilities
- **Depscan** - Advanced SCA findings
- **Application Inspector** - Technology analysis
- **CodeQL** - Deep static analysis
- **Trivy** - Container security
- **Snyk** - Dependency and code security
- **Any SARIF v2.1.0 compliant tool**

---

## Workflow Steps

### Step 1: Collect SARIF Files (5 minutes)

#### 1.1 Gather All SARIF Files

```bash
# Create triage working directory
mkdir -p ./vulnerability-triage
cd ./vulnerability-triage

# Copy all SARIF files to triage directory
find /path/to/project -name "*.sarif" -exec cp {} ./sarif-input/ \;

# Or specify multiple source directories
cp ~/scans/week1/*.sarif ./sarif-input/
cp ~/scans/week2/*.sarif ./sarif-input/
cp ./ci-results/*.sarif ./sarif-input/
```

#### 1.2 Validate SARIF Files

```bash
# Verify SARIF format compliance
for file in ./sarif-input/*.sarif; do
  echo "Validating $file..."
  python -m sarif_tools validate "$file"
done

# Check SARIF versions
python -m sarif_tools info ./sarif-input/*.sarif
```

**Expected Output**: List of valid SARIF files with tool names and run metadata

---

### Step 2: Consolidate Findings (5-10 minutes)

#### 2.1 Merge All SARIF Files

```bash
# Consolidate all SARIF into single file
python -m sarif_tools copy \
  --output ./consolidated.sarif \
  ./sarif-input/*.sarif

# Generate summary statistics
python -m sarif_tools summary ./consolidated.sarif
```

**Output Example**:
```
Tool: opengrep - 47 results
Tool: gitleaks - 12 results
Tool: kics - 23 results
Tool: osv-scanner - 8 results
Total: 90 results
```

#### 2.2 Deduplicate Findings

```bash
# Remove duplicate findings (same location, same rule)
python -m sarif_tools deduplicate \
  --input ./consolidated.sarif \
  --output ./consolidated-deduped.sarif

# Show deduplication statistics
python -m sarif_tools diff \
  ./consolidated.sarif \
  ./consolidated-deduped.sarif
```

---

### Step 3: Severity Classification (10-15 minutes)

#### 3.1 Extract Findings by SARIF Level

```bash
# Critical (error level)
python -m sarif_tools extract \
  --level error \
  ./consolidated-deduped.sarif \
  > ./findings-critical.sarif

# High (warning level with high confidence)
python -m sarif_tools extract \
  --level warning \
  ./consolidated-deduped.sarif \
  > ./findings-high.sarif

# Medium (warning level with medium confidence)
# Low (note level)
# Info (info level)
```

#### 3.2 Apply Priority Matrix

Use this matrix to assign P0-P3 priorities:

| SARIF Level | CWE Severity | Exploitability | CVSS Score | Priority | SLA |
|-------------|--------------|----------------|------------|----------|-----|
| error | Critical | High | 9.0-10.0 | **P0** | Fix immediately (24h) |
| error | High | Medium | 7.0-8.9 | **P1** | Fix before release (1 week) |
| warning | High | High | 7.0-8.9 | **P1** | Fix before release (1 week) |
| warning | Medium | Medium | 4.0-6.9 | **P2** | Fix in current sprint (2 weeks) |
| note | Any | Low | 0.1-3.9 | **P3** | Backlog (next quarter) |
| info | Any | Info | 0.0 | **P3** | Document or suppress |

#### 3.3 CWE-Based Prioritization

High-priority CWE categories:

```bash
# Critical CWEs (always P0/P1)
CWE-89   # SQL Injection
CWE-78   # OS Command Injection
CWE-79   # Cross-Site Scripting (XSS)
CWE-798  # Hardcoded Credentials
CWE-22   # Path Traversal
CWE-502  # Deserialization of Untrusted Data
CWE-611  # XML External Entities (XXE)
CWE-918  # Server-Side Request Forgery (SSRF)
CWE-94   # Code Injection
CWE-829  # Inclusion of Functionality from Untrusted Control Sphere

# Extract findings by CWE
grep -E "CWE-(89|78|79|798|22|502|611|918|94|829)" ./consolidated-deduped.sarif
```

---

### Step 4: False Positive Filtering (10-15 minutes)

#### 4.1 Automated False Positive Detection

```bash
# Filter findings in test code (usually lower priority)
python -m sarif_tools extract \
  --exclude-path "test/**" \
  --exclude-path "tests/**" \
  --exclude-path "**/*_test.go" \
  --exclude-path "**/*_spec.rb" \
  --exclude-path "**/*.test.js" \
  ./consolidated-deduped.sarif \
  > ./findings-production-only.sarif

# Filter findings in generated code
python -m sarif_tools extract \
  --exclude-path "**/*.generated.*" \
  --exclude-path "**/vendor/**" \
  --exclude-path "**/node_modules/**" \
  ./findings-production-only.sarif \
  > ./findings-filtered.sarif
```

#### 4.2 Manual False Positive Review

Review and suppress common false positives:

**Gitleaks False Positives:**
- Example API keys in documentation
- Test credentials in test fixtures
- Public keys (not secrets)

**Opengrep/Semgrep False Positives:**
- Sanitized input flagged as dangerous
- Safe crypto usage flagged by generic rules
- Framework-specific security patterns not recognized

**KICS False Positives:**
- Dev environment configurations (non-prod)
- Intentionally open access for public resources

#### 4.3 Create Suppression File

```yaml
# .grimbard-suppressions.yml
suppressions:
  - rule-id: gitleaks-generic-api-key
    path: docs/examples/api-usage.md
    reason: Example API key in documentation
    expires: 2026-12-31

  - rule-id: semgrep-sql-injection
    path: src/utils/sanitize.ts:45
    reason: Input is sanitized by framework before use
    reviewed-by: security-team
    reviewed-date: 2026-01-22

  - rule-id: kics-s3-bucket-public
    path: terraform/public-assets.tf
    reason: Public S3 bucket for static website hosting (intended)
    approved-by: cloud-architect
```

---

### Step 5: Organize Findings (10-15 minutes)

#### 5.1 Create Priority Directories

```bash
# Organize findings into priority buckets
mkdir -p ./findings/{P0-critical,P1-high,P2-medium,P3-low}

# Split findings by priority
python -m sarif_tools extract --level error ./findings-filtered.sarif > ./findings/P0-critical/findings.sarif
python -m sarif_tools extract --level warning ./findings-filtered.sarif > ./findings/P1-high/findings.sarif
# etc.
```

#### 5.2 Generate Per-Priority Reports

```bash
# Critical findings report
python -m sarif_tools --format markdown \
  ./findings/P0-critical/findings.sarif \
  > ./findings/P0-critical/report.md

# High findings report
python -m sarif_tools --format markdown \
  ./findings/P1-high/findings.sarif \
  > ./findings/P1-high/report.md

# Continue for P2, P3...
```

#### 5.3 Group by CWE Category

```bash
# Group findings by vulnerability type
for cwe in 89 78 79 798 22 502 611 918; do
  grep "CWE-$cwe" ./findings-filtered.sarif > "./findings/by-cwe/CWE-$cwe.sarif"
done
```

#### 5.4 Group by Tool

```bash
# Organize by source tool for tool-specific workflows
python -m sarif_tools extract --tool opengrep ./findings-filtered.sarif > ./findings/by-tool/opengrep.sarif
python -m sarif_tools extract --tool gitleaks ./findings-filtered.sarif > ./findings/by-tool/gitleaks.sarif
# etc.
```

---

### Step 6: Create Remediation Plan (10 minutes)

#### 6.1 Generate Triage Report

```bash
cat > ./TRIAGE_REPORT.md << 'EOF'
# Vulnerability Triage Report

**Triage Date**: $(date)
**SARIF Files Processed**: $(ls -1 ./sarif-input/*.sarif | wc -l)
**Total Findings**: $(python -m sarif_tools summary ./consolidated.sarif | grep "Total:" | awk '{print $2}')

---

## Executive Summary

### Findings Distribution

| Priority | Count | SLA | Status |
|----------|-------|-----|--------|
| P0 - Critical | [count] | 24 hours | ðŸ”´ Immediate action required |
| P1 - High | [count] | 1 week | ðŸŸ¡ Fix before release |
| P2 - Medium | [count] | 2 weeks | ðŸŸ¢ Current sprint |
| P3 - Low | [count] | Next quarter | âšª Backlog |

### Top Vulnerability Categories (CWE)

1. **CWE-798** - Hardcoded Credentials: [count] findings
2. **CWE-89** - SQL Injection: [count] findings
3. **CWE-79** - Cross-Site Scripting: [count] findings
4. **CWE-522** - Insufficiently Protected Credentials: [count] findings
5. **CWE-327** - Weak Cryptography: [count] findings

---

## P0 - Critical Findings (Immediate Action Required)

[List each P0 finding with:]
- **Rule ID**: [rule-id]
- **Location**: [file:line]
- **CWE**: [CWE-XXX]
- **Description**: [brief description]
- **Remediation**: [specific fix guidance]

---

## P1 - High Priority Findings (Fix Before Release)

[List each P1 finding...]

---

## Remediation Plan

### Week 1 (Current Sprint)
- [ ] Fix all P0 findings (count: [X])
- [ ] Begin P1 remediation (priority: auth/crypto issues)

### Week 2
- [ ] Complete P1 findings (count: [X])
- [ ] Triage P2 findings with product team

### Week 3-4
- [ ] Fix P2 findings (count: [X])
- [ ] Document P3 suppressions

### Next Quarter
- [ ] Address P3 backlog (count: [X])
- [ ] Re-scan to verify all fixes

---

## Tool Coverage

- âœ“ Opengrep - Code patterns
- âœ“ Gitleaks - Secrets
- âœ“ KICS - IaC security
- âœ“ OSV-Scanner - Dependencies
- âœ“ Depscan - Advanced SCA

---

## False Positive Summary

- **Total Suppressions**: [count]
- **Test Code Filtered**: [count]
- **Generated Code Filtered**: [count]
- **Documented Suppressions**: See .grimbard-suppressions.yml

---

## Next Steps

1. âœ… Triage completed
2. â³ Assign P0/P1 findings to engineers
3. â³ Create tickets in issue tracker
4. â³ Schedule remediation work
5. â³ Re-scan after fixes to verify

---

## Appendix

### Findings by Tool

| Tool | Findings | File |
|------|----------|------|
| Opengrep | [count] | findings/by-tool/opengrep.sarif |
| Gitleaks | [count] | findings/by-tool/gitleaks.sarif |
| KICS | [count] | findings/by-tool/kics.sarif |
| OSV-Scanner | [count] | findings/by-tool/osv-scanner.sarif |

### Findings by CWE

| CWE | Description | Count |
|-----|-------------|-------|
| CWE-798 | Hardcoded Credentials | [count] |
| CWE-89 | SQL Injection | [count] |
| CWE-79 | XSS | [count] |

EOF
```

#### 6.2 Generate Issue Tracker Tickets

```bash
# Generate GitHub Issues format
python -m sarif_tools issues \
  --format github \
  ./findings/P0-critical/findings.sarif \
  > ./P0-github-issues.md

# Generate JIRA format
python -m sarif_tools issues \
  --format jira \
  ./findings/P1-high/findings.sarif \
  > ./P1-jira-tickets.csv
```

---

## Output Structure

```
vulnerability-triage/
â”œâ”€â”€ sarif-input/              # Original SARIF files
â”‚   â”œâ”€â”€ opengrep.sarif
â”‚   â”œâ”€â”€ gitleaks.sarif
â”‚   â””â”€â”€ [other tools]
â”œâ”€â”€ consolidated.sarif        # All findings merged
â”œâ”€â”€ consolidated-deduped.sarif # Duplicates removed
â”œâ”€â”€ findings-filtered.sarif   # False positives removed
â”œâ”€â”€ findings/
â”‚   â”œâ”€â”€ P0-critical/
â”‚   â”‚   â”œâ”€â”€ findings.sarif
â”‚   â”‚   â””â”€â”€ report.md
â”‚   â”œâ”€â”€ P1-high/
â”‚   â”‚   â”œâ”€â”€ findings.sarif
â”‚   â”‚   â””â”€â”€ report.md
â”‚   â”œâ”€â”€ P2-medium/
â”‚   â”‚   â”œâ”€â”€ findings.sarif
â”‚   â”‚   â””â”€â”€ report.md
â”‚   â”œâ”€â”€ P3-low/
â”‚   â”‚   â”œâ”€â”€ findings.sarif
â”‚   â”‚   â””â”€â”€ report.md
â”‚   â”œâ”€â”€ by-cwe/
â”‚   â”‚   â”œâ”€â”€ CWE-89.sarif
â”‚   â”‚   â”œâ”€â”€ CWE-79.sarif
â”‚   â”‚   â””â”€â”€ [other CWEs]
â”‚   â””â”€â”€ by-tool/
â”‚       â”œâ”€â”€ opengrep.sarif
â”‚       â”œâ”€â”€ gitleaks.sarif
â”‚       â””â”€â”€ [other tools]
â”œâ”€â”€ TRIAGE_REPORT.md
â”œâ”€â”€ P0-github-issues.md
â”œâ”€â”€ P1-jira-tickets.csv
â””â”€â”€ .grimbard-suppressions.yml
```

---

## Integration with Issue Trackers

### GitHub Issues

```bash
# Bulk create issues from SARIF
gh issue create \
  --title "Security: [P0] $(cat title.txt)" \
  --body-file P0-github-issues.md \
  --label security,P0,vulnerability

# Or use GitHub Actions workflow
# .github/workflows/triage.yml
```

### JIRA

```bash
# Import CSV into JIRA
# Use JIRA's CSV import feature with P1-jira-tickets.csv

# Or use JIRA CLI
jira import csv --file P1-jira-tickets.csv --project SEC
```

### Azure DevOps

```bash
# Create work items from SARIF
az boards work-item create \
  --title "Security Finding: [rule-id]" \
  --type Bug \
  --area Security \
  --priority 0
```

---

## Best Practices

### Regular Triage Cadence

```bash
# Weekly triage workflow
# Monday: Collect all SARIF from CI/CD runs
find ./ci-results -name "*.sarif" -mtime -7 -exec cp {} ./weekly-triage/ \;

# Tuesday: Run triage
/grimbard-triage ./weekly-triage

# Wednesday: Team review meeting
# Review TRIAGE_REPORT.md
# Assign P0/P1 to engineers
# Create tickets

# Thursday-Friday: Begin remediation
```

### Sprint Planning Integration

```bash
# Before sprint planning, generate backlog
/grimbard-triage ./accumulated-findings

# Use findings/P2-medium/ for sprint capacity planning
# Reserve 20% capacity for security findings
```

### Metrics Tracking

```bash
# Track triage metrics over time
cat > ./metrics.json << EOF
{
  "date": "$(date -I)",
  "total_findings": $(python -m sarif_tools summary ./consolidated.sarif | grep Total | awk '{print $2}'),
  "p0_count": $(python -m sarif_tools summary ./findings/P0-critical/findings.sarif | grep Total | awk '{print $2}'),
  "p1_count": $(python -m sarif_tools summary ./findings/P1-high/findings.sarif | grep Total | awk '{print $2}'),
  "false_positive_rate": "[calculate from suppressions]"
}
EOF

# Append to historical metrics
cat ./metrics.json >> ./historical-metrics.jsonl
```

---

## Advanced Triage Techniques

### Exploitability Scoring

Apply CVSS-like scoring to prioritize:

```bash
# Factors to consider:
# - Attack Vector (Network, Adjacent, Local, Physical)
# - Attack Complexity (Low, High)
# - Privileges Required (None, Low, High)
# - User Interaction (None, Required)
# - Confidentiality Impact (High, Low, None)
# - Integrity Impact (High, Low, None)
# - Availability Impact (High, Low, None)

# Example: Network-accessible SQL injection with no auth required
# Attack Vector: Network (high)
# Attack Complexity: Low (high)
# Privileges Required: None (high)
# Impact: High (high)
# Result: P0 - Critical
```

### Business Context Prioritization

```bash
# Add business context metadata
# .grimbard-context.yml
business_context:
  - path: src/payment/
    sensitivity: critical
    multiplier: 2.0  # Double priority for payment code

  - path: src/admin/
    sensitivity: high
    multiplier: 1.5

  - path: src/marketing/
    sensitivity: low
    multiplier: 0.5
```

### Historical Trend Analysis

```bash
# Compare current triage to previous week
python -m sarif_tools diff \
  ./previous-week/consolidated.sarif \
  ./consolidated.sarif \
  > ./triage-delta.md

# Track: new findings, resolved findings, recurring issues
```

---

## Success Criteria

Triage is successful when:

- âœ“ All SARIF files validated and consolidated
- âœ“ Duplicates removed
- âœ“ False positives filtered
- âœ“ Findings organized into P0-P3 buckets
- âœ“ TRIAGE_REPORT.md generated
- âœ“ Issue tracker tickets created for P0/P1
- âœ“ Remediation plan documented
- âœ“ Sprint backlog updated

---

## Troubleshooting

### SARIF Validation Errors

```bash
# Check SARIF schema version
jq '.version' ./problematic.sarif

# Convert SARIF 1.0 to 2.1.0
python -m sarif_tools upgrade ./v1.sarif --output ./v2.sarif
```

### Deduplication Not Working

```bash
# Manual deduplication by location + rule
jq '[.runs[].results[] | {location: .locations[0].physicalLocation, ruleId}] | unique' ./consolidated.sarif
```

### Too Many False Positives

```bash
# Review suppression rules
# Add more specific exclusions in .grimbard-suppressions.yml

# Or configure tool-specific suppressions in config/tools.yml
```

---

## Next Steps After Triage

### If P0 Findings Exist

1. **Immediate Action** (within 24h):
   - Assign to senior engineers
   - Create incident tickets
   - Notify security team and management
   - Begin remediation immediately
   - Consider hotfix release

### If Only P1/P2 Findings

1. **Plan Remediation**:
   - Create sprint tickets
   - Estimate effort
   - Schedule fixes before next release
   - Track progress daily

### For Ongoing Security

1. **Continuous Triage**:
   - Run weekly triage on CI/CD findings
   - Track metrics (trend analysis)
   - Refine false positive filters
   - Update priority matrix based on lessons learned

---

## References

- [SARIF Specification v2.1.0](https://docs.oasis-open.org/sarif/sarif/v2.1.0/)
- [CVSS v3.1 Calculator](https://www.first.org/cvss/calculator/3.1)
- [CWE Top 25](https://cwe.mitre.org/top25/)
- [OWASP Risk Rating](https://owasp.org/www-community/OWASP_Risk_Rating_Methodology)
- [Complete Security Review Workflow](secure-code-review.md)
- [Quick Scan Workflow](quick-scan.md)
